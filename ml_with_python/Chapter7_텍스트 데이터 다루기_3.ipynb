{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mglearn\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "from mpl_toolkits.mplot3d import Axes3D, axes3d\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import nltk\n",
    "from konlpy.tag import Okt\n",
    "import graphviz\n",
    "from sklearn.utils.fixes import loguniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = load_files('aclImdb/train/')\n",
    "text_train, y_train = reviews_train['data'], reviews_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = [doc.replace(b'<br/>', b'') for doc in text_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12500, 12500], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test = load_files('aclImdb/test/')\n",
    "text_test, y_test = reviews_test['data'], reviews_test['target']\n",
    "text_test = [doc.replace(b'<br/>', b'') for doc in text_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bards_words = ['The fool doth think he is wise,', 'but the wise man knows himself to be a fool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 9,\n",
       " 'fool': 3,\n",
       " 'doth': 2,\n",
       " 'think': 10,\n",
       " 'he': 4,\n",
       " 'is': 6,\n",
       " 'wise': 12,\n",
       " 'but': 1,\n",
       " 'man': 8,\n",
       " 'knows': 7,\n",
       " 'himself': 5,\n",
       " 'to': 11,\n",
       " 'be': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer().fit(bards_words)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1],\n",
       "       [1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words = vect.transform(bards_words)\n",
    "bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer().fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "X_test = vect.transform(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '0000000000001', ..., 'østbye', 'über', 'üvegtigris'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\"Dutch Schultz\", AKA Arthur Fleggenheimer, was a real person and his rather nasty life is fairly well documented. This movie which purports to depict his life should have used a fictional character, because the overdramatized events are too strong a departure from the facts and the chronology. Not only that, it ignores some interesting details which other versions have included such as the public relations fiasco in upstate N.Y. and his religious conversion. It is true that he was executed by Luciano, Lansky, et. al. but that\\'s as far as it goes. The exploding plate scene which represents Luciano carrying out the execution of Bo Weinberg in his own home, assisted by his own mother is rediculous. Also, there is the scene in which Dutch approaches his own mother to pay protection to Legs Diamond. It just doesn\\'t work. The character of Mrs. Fleggenheimer doesn\\'t work either. This movie does not need a doting Jewish mother for comic relief. The lame representation of Legs Diamond was humorous enough. I\\'m sure the man is turning in his grave. And, by the way, Dutch did in fact personally kill people, but, he was not Rambo or 007. The scene in which he wipes out the brewery is absurd. I don\\'t know. Maybe it was supposed to be a comedy and I just didn\\'t get it.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[text_train[i] for i in np.argwhere(X_train[:, 9] == 1)[:, 0]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  554,     0],\n",
       "       [ 6583,     0],\n",
       "       [ 7758,     0],\n",
       "       [ 9637,     0],\n",
       "       [10764,     0],\n",
       "       [15068,     0],\n",
       "       [16627,     0],\n",
       "       [17873,     0],\n",
       "       [22458,     0],\n",
       "       [23321,     0],\n",
       "       [23473,     0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train[:, 9] == 1이 (-1, 1) 형태의 shape이기에 argwhere가 [n, 0] 형태로 나타남\n",
    "np.argwhere(X_train[:, 9] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87912"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=0.1, max_iter=5000).fit(X_train, y_train)\n",
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df=5).fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "X_test = vect.transform(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87848"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=0.1, max_iter=5000).fit(X_train, y_train)\n",
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "610a6f344c2137faf927ea819c63f6cee33a2c04455044b28099f39fe9722347"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
